# VARIABLE DESCRIPTIONS:
# survival        Survival
#                 (0 = No; 1 = Yes)
# pclass          Passenger Class
#                 (1 = 1st; 2 = 2nd; 3 = 3rd)
# name            Name
# sex             Sex
# age             Age
# sibsp           Number of Siblings/Spouses Aboard
# parch           Number of Parents/Children Aboard
# ticket          Ticket Number
# fare            Passenger Fare
# cabin           Cabin
# embarked        Port of Embarkation
#                 (C = Cherbourg; Q = Queenstown; S = Southampton)
# 
# SPECIAL NOTES:
# Pclass is a proxy for socio-economic status (SES)
#  1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower
# 
# Age is in Years; Fractional if Age less than One (1)
#  If the Age is Estimated, it is in the form xx.5
# 
# With respect to the family relation variables (i.e. sibsp and parch)
# some relations were ignored.  The following are the definitions used
# for sibsp and parch.
# 
# Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic
# Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)
# Parent:   Mother or Father of Passenger Aboard Titanic
# Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic
# 
# Other family relatives excluded from this study include cousins,
# nephews/nieces, aunts/uncles, and in-laws.  Some children travelled
# only with a nanny, therefore parch=0 for them.  As well, some
# travelled with very close friends or neighbors in a village, however,
# the definitions do not support such relations.

import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import re
import warnings

%matplotlib inline

os.chdir("/Users/charlmarais/projects/ds4a_titanic")
os.getcwd()

# Load data
train_df = pd.read_csv("train.csv")
test_df  = pd.read_csv("test.csv")

# Join tables

# Dummy survive variable and train/test variable
test_df["Survived"] = 0
test_df["Set"] = "test"
train_df["Set"] = "train"
# Combine
total_df = pd.concat([train_df, test_df])

# List variables
train_df.info() # Age and Cabin has missing values
train_df.head()

######################
# Descriptive Checks #
######################
train_df['Survived'].value_counts(normalize = True)
train_df['Survived'].mean()

##################################
# Passanger Class #
###################
train_df['Survived'].groupby(train_df['Pclass']).mean()
# Class 3 was clearly less likely to survive

##################################
# Name #
########
train_df['Title'] = train_df['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])
train_df['Title'].value_counts()
train_df['Survived'].groupby(train_df['Title']).mean()
# Mr much less likely to survive

##################################
# Sex #
#######
train_df['Sex'].value_counts(normalize = True)
train_df['Survived'].groupby(train_df['Sex']).mean()

##################################
# Age #
#######
train_df['Survived'].groupby(train_df['Age'].isnull()).mean()
pd.qcut(train_df['Age'],5).value_counts()

##################################
# Sibling Spouse #
##################
train_df['Survived'].groupby(train_df['SibSp']).mean()
train_df['SibSp'].value_counts()


#################################
# Parents and Childrend #
#########################





#####################################
#        Feature Engineering        #
#####################################

# Names
Names1 = pd.Series(total_df["Name"])

Names2 = Names1.str.extract('(.*)\,(.*)\.(.*)\(?')
Names3 = pd.Series(Names2[2])
Names2[3] = Names3.str.extract('\((.*?)\)')

Names4 = pd.Series(Names2[2])
Names5 = Names4.str.extract('(.*)\(')
Names5[Names5.isnull()] = Names4[Names5.isnull()]
Names5 = Names5.str.strip(" ")
Names5 = Names5.str.replace('""', '')
Names2[2] = Names5

# last name, title. first name (person original name)
# Smith, Mrs. Lucien Philip (Mary Eloise Hughes)

Names2.columns = ['last_name', 'title', 'first_name', 'husband_name']
Names2.last_name    = Names2.last_name.str.strip(" ")
Names2.title        = Names2.title.str.strip(" ")
Names2.first_name   = Names2.first_name.str.strip(" ")
Names2.husband_name = Names2.husband_name.str.strip(" ")

Names_orig   = pd.Series(list(Names2["husband_name"]))
Names_orig2  = pd.Series(list(Names2["husband_name"]))
Names_fn     = pd.Series(list(Names2["first_name"]))
Names_orig[Names_orig.isnull()]    = Names_fn[Names_orig.isnull()]
Names_orig2[Names_orig2.notnull()] = Names_fn[Names_orig2.notnull()]

Names2["husband_name"] = pd.Series(list(Names_orig2))
Names2["first_name"]   = pd.Series(list(Names_orig))

total_df = pd.concat([total_df, Names2], axis = 1)
total_df = total_df.drop("Name", 1)

# Correcting titles
total_df['title'].value_counts()
total_df.title[total_df.title.isin(["Mr", "Capt", "Sir", "Don", "Major", "Col"])] = "Mr"
total_df.title[total_df.title.isin(["Master", "Jonkheer"])] = "Master"
total_df.title[total_df.title.isin(["Miss", "Mlle", "Ms", "Lady"])] = "Miss"
total_df.title[total_df.title.isin(["Mrs", "the Countess", "Mme", "Mrs. Martin (Elizabeth L", "Dona"])] = "Mrs"

# Age and Fare
grouped = total_df.groupby(['Sex', 'Pclass', 'title'])[["Age", "Fare"]]
grouped.median()

total_df["Age"] = total_df.groupby(['Sex', 'Pclass', 'title'])[["Age"]].transform(lambda x: x.fillna(x.median()))
total_df["Fare"] = total_df.groupby(['Sex', 'Pclass', 'title'])[["Fare"]].transform(lambda x: x.fillna(x.median()))
total_df.info()
total_df.describe()

# Bin age and Fare (temp)
total_df['age_group']  = pd.cut(total_df.Age, range(0, 85, 20))
total_df['fare_group'] = pd.cut(total_df.Fare, range(0, 550, 20), right = False)

# Embarked and Cabin
# Categorical Imputation
def cat_imputer(df, vars_in, cat_imp):
    temp_main = df[vars_in + cat_imp]
    # Add sequence to get correct sequence at end
    temp_main["seq"] = list(range(0, len(temp_main), 1))
    # Concatenate all variables to create unique levels
    temp_main["key"] = ""
    for v in vars_in :
        temp_main["key"] = temp_main.apply(lambda x:'%s%s' % (x["key"], x[v]), axis = 1)
    
    unique_levs = temp_main["key"].unique()
    # Loop through each key and for each key find the most observed values
    for lev in unique_levs :
        temp_df = temp_main[temp_main["key"] == lev]
        if temp_df[cat_imp[0]].isnull().sum() - len(temp_df) == 0 :
            imputer = temp_main[cat_imp[0]].value_counts().argmax()
            warnings.warn("Some categories got the overall median, restrict the vars_in argument or reduce the strictness of the bindings to have more granular imputations")
        else :
            imputer = temp_df[cat_imp[0]].value_counts().argmax()
            
        temp_df = temp_df.replace(['nan', 'NaN', 'None', np.NaN], imputer)
        if lev != unique_levs[0] :
            temp_df_fin = temp_df_fin.append(temp_df)
        else :
            temp_df_fin = temp_df
    
    # Sort 
    temp_df_fin = temp_df_fin.sort('seq')
    
    # Return the cat_imp column in the original df
    return temp_df_fin[cat_imp[0]]


total_df["Embarked"] = cat_imputer(total_df, ['Sex', 'Pclass', 'title', 'fare_group', 'age_group'], ["Embarked"])
total_df["Cabin"]    = cat_imputer(total_df, ['Sex', 'Pclass', 'title', 'fare_group', 'age_group'], ["Cabin"])

# Impose none for blank husband names
total_df.husband_name = total_df.husband_name.replace(['nan', 'NaN', 'None', np.NaN], "None")

# Drop bandings
total_df = total_df.drop("fare_group", 1)
total_df = total_df.drop("age_group", 1)

total_df.info()
# Create dummy variables
dummies_title   = pd.get_dummies(total_df.title)
dummies_cabin   = pd.get_dummies(total_df.Cabin)
dummies_embar   = pd.get_dummies(total_df.Embarked)
dummies_gendr   = pd.get_dummies(total_df.Sex)
dummies_tickt   = pd.get_dummies(total_df.Ticket)
dummies_last_n  = pd.get_dummies(total_df.last_name)
dummies_first_n = pd.get_dummies(total_df.first_name)
dummies_husbn_n = pd.get_dummies(total_df.husband_name)

model_data = total_df.drop(['title', 'Cabin', 'Embarked', 'Sex', 'Ticket', 'last_name', 'first_name', 'husband_name'], axis = 1)
model_data = pd.concat([model_data, 
                        dummies_title,
                        dummies_cabin,
                        dummies_embar,
                        dummies_gendr,
                        dummies_tickt,
                        dummies_last_n,
                        dummies_first_n,
                        dummies_husbn_n], axis = 1)

# Scale features
features = list(model_data.columns)
features.remove('PassengerId')
combined[features] = combined[features].apply(lambda x: x/x.max(), axis=0)
    

# Split between train and test from test.csv
model_train = model_data[model_data.Set == "train"]
model_test  = model_data[model_data.Set == "test"]
model_train = model_train.drop(['Set'], axis = 1)
model_test  = model_test.drop(['Set'], axis = 1)









